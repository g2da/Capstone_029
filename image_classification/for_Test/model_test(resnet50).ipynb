{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models,transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),transforms.ToTensor(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]             )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = True).cuda()\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'tench,잉어',\n",
      "tench\n"
     ]
    }
   ],
   "source": [
    "with open(\"1.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "print(classes[0])\n",
    "result = classes[0].split(':')\n",
    "result = result[1][2:-2].split(',')\n",
    "print(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image2(image):\n",
    "    img_t = transform(image)\n",
    "    batch_t = torch.unsqueeze(img_t,0).cuda()\n",
    "    out = model(batch_t)\n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    #result = [(classes[idx], percentage[idx].item()) for idx in indices[0][:1]]\n",
    "    result = [classes[idx] for idx in indices[0][:1]]\n",
    "    print(result)\n",
    "    result = result[0].split(':')\n",
    "    result = result[1][2:-2].split(',')\n",
    "    \n",
    "    res_eng = result[0]\n",
    "    res_kor = result[1]\n",
    "    \n",
    "    return res_eng,res_kor.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"954: 'banana, 바나나',\"]\n",
      "banana\n",
      "바나나\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"banana1.png\")\n",
    "a,b = predict_image2(img)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"415: 'bakery, 빵집',\", 93.50230407714844), (\"616: 'knot, 매듭',\", 4.63231897354126), (\"466: 'bullet train,초고속 열차',\", 0.3151971697807312), (\"598: 'home theater, 홈 시어터',\", 0.2893153727054596), (\"771: 'safe, 금고',\", 0.2632297873497009)]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"bag1.jpg\")\n",
    "predict_image2(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"505: 'coffeepot, 커피포트',\", 96.95236206054688), (\"969: 'eggnog, 에그노그',\", 2.305882692337036), (\"968: 'cup, 컵',\", 0.30023640394210815), (\"506: 'spiral, 나선형',\", 0.1521705538034439), (\"726: 'plane, 대패',\", 0.04028190299868584)]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"cup.jpg\")\n",
    "predict_image2(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    img_t = transform(image)\n",
    "    batch_t = torch.unsqueeze(img_t,0).cuda()\n",
    "    \n",
    "    output = model(batch_t)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
